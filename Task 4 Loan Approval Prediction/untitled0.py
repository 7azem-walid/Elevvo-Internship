# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oyb2mZhJMuB2Ur_85F4QWgGBQYqZNbKP
"""

import os
import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (
    classification_report, precision_score, recall_score, f1_score, confusion_matrix
)
import matplotlib.pyplot as plt
import joblib
try:
    from imblearn.over_sampling import SMOTE
    from imblearn.pipeline import Pipeline as ImbPipeline
    IMBLEARN_AVAILABLE = True
except Exception:
    IMBLEARN_AVAILABLE = False

# Load the dataset
data = pd.read_csv('/content/loan_approval_dataset.csv')

#checking duplicates
data.duplicated().sum()

# Get descriptive statistics for numerical columns
data.describe()

#first 5 rows of the dataset
data.head()

#summary about dataframe
data.info()

print(" Data Loaded")
print(f"Shape: {data.shape}")
print("Columns:", list(data.columns))
print(data.head(3))

preferred_names = [
    "loan_status", "approved", "is_approved", "status", "target", "label"
]

def pick_target_column(dataframe):
    cols = list(dataframe.columns)

    for name in preferred_names:
        if name in [c.strip().lower() for c in cols]:
            for c in cols:
                if c.strip().lower() == name:
                    if dataframe[c].nunique(dropna=True) == 2:
                        return c

    for c in cols:
        if dataframe[c].nunique(dropna=True) == 2:
            return c
    return None

target_col = pick_target_column(data)
print(f"Target detected: {target_col}")

y_raw = data[target_col]

def normalize_binary_target(series):
    s = series.astype(str).str.strip().str.lower()
    mapping = {"approved":1, "y":1, "yes":1, "1":1, "true":1,
               "rejected":0, "n":0, "no":0, "0":0, "false":0}
    mapped = s.map(mapping)
    if mapped.isna().sum() == 0:
        return mapped.astype(int)
    else:
        # fallback: map unique values
        uniq = s.unique()
        return s.map({uniq[0]:0, uniq[1]:1}).astype(int)

y = normalize_binary_target(y_raw)
X = data.drop(columns=[target_col])

print(" Target normalized (0=Rejected, 1=Approved)")
print(y.value_counts())

numeric_features = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
categorical_features = [c for c in X.columns if c not in numeric_features]

print("Features")
print("Numeric:", numeric_features)
print("Categorical:", categorical_features)

numeric_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

categorical_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer([
    ("num", numeric_pipeline, numeric_features),
    ("cat", categorical_pipeline, categorical_features)
])

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(" Train/Test Split")
print("Train size:", X_train.shape)
print("Test size :", X_test.shape)

log_reg_balanced = Pipeline([
    ("pre", preprocessor),
    ("clf", LogisticRegression(max_iter=1000, class_weight="balanced", random_state=42))
])

tree_balanced = Pipeline([
    ("pre", preprocessor),
    ("clf", DecisionTreeClassifier(class_weight="balanced", random_state=42))
])

print(" Models ready")

if IMBLEARN_AVAILABLE:
    log_reg_smote = ImbPipeline([
        ("pre", preprocessor),
        ("smote", SMOTE(random_state=42)),
        ("clf", LogisticRegression(max_iter=1000, random_state=42))
    ])

    tree_smote = ImbPipeline([
        ("pre", preprocessor),
        ("smote", SMOTE(random_state=42)),
        ("clf", DecisionTreeClassifier(random_state=42))
    ])
    print("SMOTE Pipelines prepared")
else:
    log_reg_smote, tree_smote = None, None
    print(" imblearn not available, skipping SMOTE")

def evaluate_model(name, model, X_tr, y_tr, X_te, y_te):
    model.fit(X_tr, y_tr)
    y_pred = model.predict(X_te)

    precision = precision_score(y_te, y_pred, zero_division=0)
    recall = recall_score(y_te, y_pred, zero_division=0)
    f1 = f1_score(y_te, y_pred, zero_division=0)

    print(f"\n=== {name} ===")
    print("Precision:", round(precision,4))
    print("Recall   :", round(recall,4))
    print("F1-score :", round(f1,4))
    print("\nReport:\n", classification_report(y_te, y_pred, zero_division=0))

    cm = confusion_matrix(y_te, y_pred)
    plt.imshow(cm, cmap="Blues")
    plt.title(f"Confusion Matrix â€” {name}")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    for (i,j), val in np.ndenumerate(cm):
        plt.text(j,i,val,ha="center",va="center")
    plt.show()

    return {"model":name,"precision":precision,"recall":recall,"f1":f1}

results = []
results.append(evaluate_model("LogReg (balanced)", log_reg_balanced, X_train, y_train, X_test, y_test))
results.append(evaluate_model("DecisionTree (balanced)", tree_balanced, X_train, y_train, X_test, y_test))

if log_reg_smote:
    results.append(evaluate_model("LogReg + SMOTE", log_reg_smote, X_train, y_train, X_test, y_test))
    results.append(evaluate_model("DecisionTree + SMOTE", tree_smote, X_train, y_train, X_test, y_test))

results_df = pd.DataFrame(results).sort_values("f1", ascending=False)
print("Model Comparison")
print(results_df)

best_name = results_df.iloc[0]["model"]
name_to_model = {
    "LogReg (balanced)": log_reg_balanced,
    "DecisionTree (balanced)": tree_balanced,
    "LogReg + SMOTE": log_reg_smote,
    "DecisionTree + SMOTE": tree_smote
}
best_model = name_to_model[best_name]
best_model.fit(X, y)

joblib.dump(best_model, "best_loan_model.pkl")
results_df.to_csv("loan_model_evaluation.csv", index=False)

print(" Saved Best Model:", best_name)

def predict_single(sample_dict, model_path="best_loan_model.pkl"):
    model = joblib.load(model_path)
    X_single = pd.DataFrame([sample_dict])
    return int(model.predict(X_single)[0])

print(" Inference Ready")